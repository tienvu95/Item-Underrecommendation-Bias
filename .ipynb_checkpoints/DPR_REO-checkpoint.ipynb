{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d4703ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import argparse\n",
    "import utility\n",
    "import pandas as pd\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8ae48f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DPR_REO:\n",
    "\n",
    "    def __init__(self, sess, args, train_df, vali_df, item_genre, genre_error_weight\n",
    "                 , key_genre, item_genre_list, user_genre_count):\n",
    "        self.dataname = args.dataname\n",
    "\n",
    "        self.layers = eval(args.layers)\n",
    "\n",
    "        self.key_genre = key_genre\n",
    "        self.item_genre_list = item_genre_list\n",
    "        self.user_genre_count = user_genre_count\n",
    "\n",
    "        self.sess = sess\n",
    "        self.args = args\n",
    "\n",
    "        self.num_cols = len(train_df['item_id'].unique())\n",
    "        self.num_rows = len(train_df['user_id'].unique())\n",
    "\n",
    "        self.hidden_neuron = args.hidden_neuron\n",
    "        self.neg = args.neg\n",
    "        self.batch_size = args.batch_size\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.vali_df = vali_df\n",
    "        self.num_train = len(self.train_df)\n",
    "        self.num_vali = len(self.vali_df)\n",
    "\n",
    "        self.train_epoch = args.train_epoch\n",
    "        self.train_epoch_a = args.train_epoch_a\n",
    "        self.display_step = args.display_step\n",
    "\n",
    "        self.lr_r = args.lr_r  # learning rate\n",
    "        self.lr_a = args.lr_a  # learning rate\n",
    "\n",
    "        self.reg = args.reg  # regularization term trade-off\n",
    "        self.reg_s = args.reg_s\n",
    "\n",
    "        self.num_genre = args.num_genre\n",
    "        self.alpha = args.alpha\n",
    "        self.item_genre = item_genre\n",
    "        self.genre_error_weight = genre_error_weight\n",
    "\n",
    "        self.genre_count_list = []\n",
    "        for k in range(self.num_genre):\n",
    "            self.genre_count_list.append(np.sum(item_genre[:, k]))\n",
    "\n",
    "        print('**********DPR_REO**********')\n",
    "        print(self.args)\n",
    "        self._prepare_model()\n",
    "\n",
    "\n",
    "    #load bpr checkpoint\n",
    "    def loadmodel(self, saver, checkpoint_dir):\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def run(self):\n",
    "        init = tf.compat.v1.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "        saver = tf.compat.v1.train.Saver([self.P, self.Q])\n",
    "        self.loadmodel(saver, \"./\"+self.dataname+\"/BPR_check_points\")\n",
    "        print (\"restore done\")\n",
    "\n",
    "        for epoch_itr in range(1, self.train_epoch + 1 + self.train_epoch_a):\n",
    "            print(\"starting itr \" + str(epoch_itr))\n",
    "            self.train_model(epoch_itr)\n",
    "            if epoch_itr % self.display_step == 0:\n",
    "                self.test_model(epoch_itr)\n",
    "            print(\"end itr \" + str(epoch_itr))\n",
    "        return self.make_records()\n",
    "\n",
    "    def _prepare_model(self):\n",
    "        with tf.name_scope(\"input_data\"):\n",
    "            # declare embedding u i j, genre to predict\n",
    "            self.user_input = tf.compat.v1.placeholder(tf.int32, shape=[None, 1], name=\"user_input\")\n",
    "            self.item_input_pos = tf.compat.v1.placeholder(tf.int32, shape=[None, 1], name=\"item_input_pos\")\n",
    "            self.item_input_neg = tf.compat.v1.placeholder(tf.int32, shape=[None, 1], name=\"item_input_neg\")\n",
    "\n",
    "            self.input_item_genre = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, self.num_genre]\n",
    "                                                   , name=\"input_item_genre\")\n",
    "            self.input_item_error_weight = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, 1]\n",
    "                                                          , name=\"input_item_error_weight\")\n",
    "        #this is the part initialize BPR for MF\n",
    "        with tf.compat.v1.variable_scope(\"BPR\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            self.P = tf.compat.v1.get_variable(name=\"P\",\n",
    "                                     initializer=tf.compat.v1.truncated_normal(shape=[self.num_rows, self.hidden_neuron], mean=0,\n",
    "                                                                     stddev=0.03), dtype=tf.float32)\n",
    "            self.Q = tf.compat.v1.get_variable(name=\"Q\",\n",
    "                                     initializer=tf.compat.v1.truncated_normal(shape=[self.num_cols, self.hidden_neuron], mean=0,\n",
    "                                                                     stddev=0.03), dtype=tf.float32)\n",
    "        para_r = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=\"BPR\")\n",
    "\n",
    "\n",
    "        #adversary as a mlp\n",
    "        with tf.compat.v1.variable_scope(\"Adversarial\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            num_layer = len(self.layers)\n",
    "            adv_W = []\n",
    "            adv_b = []\n",
    "            for l in range(num_layer):\n",
    "                if l == 0:\n",
    "                    in_shape = 1\n",
    "                else:\n",
    "                    in_shape = self.layers[l - 1]\n",
    "                adv_W.append(tf.compat.v1.get_variable(name=\"adv_W\" + str(l),\n",
    "                                             initializer=tf.compat.v1.truncated_normal(shape=[in_shape, self.layers[l]],\n",
    "                                                                             mean=0, stddev=0.03), dtype=tf.float32))\n",
    "                adv_b.append(tf.compat.v1.get_variable(name=\"adv_b\" + str(l),\n",
    "                                             initializer=tf.compat.v1.truncated_normal(shape=[1, self.layers[l]],\n",
    "                                                                             mean=0, stddev=0.03), dtype=tf.float32))\n",
    "            adv_W_out = tf.compat.v1.get_variable(name=\"adv_W_out\",\n",
    "                                        initializer=tf.compat.v1.truncated_normal(shape=[self.layers[-1], self.num_genre],\n",
    "                                                                        mean=0, stddev=0.03), dtype=tf.float32)\n",
    "\n",
    "            adv_b_out = tf.compat.v1.get_variable(name=\"adv_b_out\",\n",
    "                                        initializer=tf.compat.v1.truncated_normal(shape=[1, self.num_genre],\n",
    "                                                                        mean=0, stddev=0.03), dtype=tf.float32)\n",
    "        para_a = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=\"Adversarial\")\n",
    "\n",
    "\n",
    "        ##prep embedding for bpr\n",
    "        p = tf.reduce_sum(tf.nn.embedding_lookup(self.P, self.user_input), 1)\n",
    "        self.p = p\n",
    "        q_neg = tf.reduce_sum(tf.nn.embedding_lookup(self.Q, self.item_input_neg), 1)\n",
    "        self.q_neg = q_neg\n",
    "        q_pos = tf.reduce_sum(tf.nn.embedding_lookup(self.Q, self.item_input_pos), 1)\n",
    "        self.q_pos = q_pos\n",
    "        ##prediction based on bpr embedding\n",
    "        predict_pos = tf.reduce_sum(p * q_pos, 1)\n",
    "        self.predict_pos = predict_pos\n",
    "        predict_neg = tf.reduce_sum(p * q_neg, 1)\n",
    "        self.predict_neg = predict_neg\n",
    "        r_cost1 = tf.reduce_sum(tf.nn.softplus(-(predict_pos - predict_neg))) #bpr cost\n",
    "        r_cost2 = self.reg * 0.5 * (self.l2_norm(self.P) + self.l2_norm(self.Q))  # regularization term\n",
    "        pred = tf.matmul(self.P, tf.transpose(self.Q))\n",
    "        self.s_mean = tf.reduce_mean(pred, axis=1)\n",
    "        self.s_std = tf.keras.backend.std(pred, axis=1)\n",
    "        self.s_cost = tf.reduce_sum(tf.square(self.s_mean) + tf.square(self.s_std) - 2 * tf.compat.v1.log(self.s_std) - 1)\n",
    "        self.r_cost = r_cost1 + r_cost2 + self.reg_s * 0.5 * self.s_cost\n",
    "\n",
    "\n",
    "        #last layer = prediction by the mlp adversary\n",
    "        adv_last = tf.reshape(tf.concat([predict_pos, predict_neg], axis=0), [tf.shape(self.input_item_genre)[0], 1])\n",
    "        self.adv_last_prem = adv_last\n",
    "        for l in range(num_layer):\n",
    "            adv = tf.nn.relu(tf.matmul(adv_last, adv_W[l]) + adv_b[l])\n",
    "            adv_last = adv #linear-relu\n",
    "            self.adv_last = adv_last\n",
    "        #sigmoid to convert output to prediction\n",
    "        self.adv_output = tf.nn.sigmoid(tf.matmul(adv_last, adv_W_out) + adv_b_out)\n",
    "\n",
    "        #adversarial cost (why they have the input_item_error_weight??)\n",
    "        self.a_cost = tf.reduce_sum(tf.square(self.adv_output - self.input_item_genre) * self.input_item_error_weight)\n",
    "\n",
    "        self.all_cost = self.r_cost - self.alpha * self.a_cost  # the loss function\n",
    "\n",
    "        #optimize for bpr, adversary and overall cost wrt to overall obj function\n",
    "        with tf.compat.v1.variable_scope(\"Optimizer\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            self.r_optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr_r).minimize(self.r_cost, var_list=para_r)\n",
    "            self.a_optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr_a).minimize(self.a_cost, var_list=para_a)\n",
    "            self.all_optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr_r).minimize(self.all_cost, var_list=para_r)\n",
    "\n",
    "    def train_model(self, itr):\n",
    "        NS_start_time = time.time() * 1000.0\n",
    "        epoch_r_cost = 0.0\n",
    "        epoch_s_cost = 0.0\n",
    "        epoch_s_mean = 0.0\n",
    "        epoch_s_std = 0.0\n",
    "        epoch_a_cost = 0.0\n",
    "        num_sample, user_list, item_pos_list, item_neg_list = utility.negative_sample(self.train_df, self.num_rows,\n",
    "                                                                                      self.num_cols, self.neg)\n",
    "        NS_end_time = time.time() * 1000.0\n",
    "\n",
    "        start_time = time.time() * 1000.0\n",
    "        num_batch = int(num_sample / float(self.batch_size)) + 1\n",
    "        random_idx = np.random.permutation(num_sample)\n",
    "        for i in range(num_batch):\n",
    "            # get the indices of the current batch\n",
    "            if i == num_batch - 1:\n",
    "                batch_idx = random_idx[i * self.batch_size:]\n",
    "            elif i < num_batch - 1:\n",
    "                batch_idx = random_idx[(i * self.batch_size):((i + 1) * self.batch_size)]\n",
    "\n",
    "            if itr > self.train_epoch:\n",
    "                random_idx_a = np.random.permutation(num_sample)\n",
    "                print(\"start itr \" + str(itr) + \"for batch \" + str(i))\n",
    "                for j in range(num_batch):\n",
    "                    if j == num_batch - 1:\n",
    "                        batch_idx_a = random_idx_a[j * self.batch_size:]\n",
    "                    elif j < num_batch - 1:\n",
    "                        batch_idx_a = random_idx_a[(j * self.batch_size):((j + 1) * self.batch_size)]\n",
    "                    item_idx_list = ((item_pos_list[batch_idx_a, :]).reshape((len(batch_idx_a)))).tolist()\n",
    "                    a_opt, tmp_a_cost, p, q_pos,q_neg, predict_pos, adv_last_prem,adv_last, adv_output = self.sess.run(  # do the optimization by the minibatch\n",
    "                        [self.a_optimizer, self.a_cost, self.p, self.q_pos,self.q_neg, self.predict_pos, self.adv_last_prem,self.adv_last,self.adv_output ], #update the adversary\n",
    "                        feed_dict={self.user_input: user_list[batch_idx_a, :],\n",
    "                                   self.item_input_pos: item_pos_list[batch_idx_a, :],\n",
    "                                   self.item_input_neg: item_neg_list[batch_idx_a, :],\n",
    "                                   self.input_item_genre: self.item_genre[item_idx_list, :],\n",
    "                                   self.input_item_error_weight: self.genre_error_weight[item_idx_list, :]})\n",
    "                    epoch_a_cost += tmp_a_cost\n",
    "                    print(\"update epoch_a_cost done \" + str(j))\n",
    "                    print(\"Shape of p = \" + str(p.shape) +\" sample of an embedding\")\n",
    "                    print(p[1,:])\n",
    "                    print(\"Shape of q_pos = \" + str(q_pos.shape)+\" sample of an embedding\")\n",
    "                    print(q_pos[1,:])\n",
    "                    print(\"Shape of predict_pos = \" + str(predict_pos.shape)+\" sample of some predictions\")\n",
    "                    print(predict_pos[1:5])\n",
    "                    print(\"Shape of input to adversary = \" + str(adv_last_prem.shape) +\" sample of an input\")\n",
    "                    print(adv_last_prem[1:5,:])\n",
    "#                     print(\"Shape of adv_activated = \" + str(adv_last.shape))\n",
    "                    print(\"Shape of adv_output = \" + str(adv_output.shape) +\" sample of an output\")\n",
    "                    print(adv_output[1:5,:])\n",
    "                item_idx_list = ((item_pos_list[batch_idx, :]).reshape((len(batch_idx)))).tolist()\n",
    "                _, tmp_r_cost, tmp_s_cost, tmp_s_mean, tmp_s_std = self.sess.run(  # do the optimization by the minibatch\n",
    "                    [self.all_optimizer, self.all_cost, self.s_cost, self.s_mean, self.s_std], # update overall objective\n",
    "                    feed_dict={self.user_input: user_list[batch_idx, :],\n",
    "                               self.item_input_pos: item_pos_list[batch_idx, :],\n",
    "                               self.item_input_neg: item_neg_list[batch_idx, :],\n",
    "                               self.input_item_genre: self.item_genre[item_idx_list, :],\n",
    "                               self.input_item_error_weight: self.genre_error_weight[item_idx_list, :]})\n",
    "                epoch_r_cost += tmp_r_cost\n",
    "                epoch_s_mean += np.mean(tmp_s_mean)\n",
    "                epoch_s_std += np.mean(tmp_s_std)\n",
    "                epoch_s_cost += tmp_s_cost\n",
    "                print(\"update epoch_s_cost done\")\n",
    "            else:#for train_epoch, we only train the classifer (BPR) then append the adversarial training phase\n",
    "                item_idx_list = ((item_pos_list[batch_idx, :]).reshape((len(batch_idx)))).tolist()\n",
    "                _, tmp_r_cost, tmp_s_cost, tmp_s_mean, tmp_s_std = self.sess.run(  # do the optimization by the minibatch\n",
    "                    [self.r_optimizer, self.r_cost, self.s_cost, self.s_mean, self.s_std], #update the weight of the classifier\n",
    "                    feed_dict={self.user_input: user_list[batch_idx, :],\n",
    "                               self.item_input_pos: item_pos_list[batch_idx, :],\n",
    "                               self.item_input_neg: item_neg_list[batch_idx, :],\n",
    "                               self.input_item_genre: self.item_genre[item_idx_list, :],\n",
    "                               self.input_item_error_weight: self.genre_error_weight[item_idx_list, :]})\n",
    "                epoch_r_cost += tmp_r_cost\n",
    "                epoch_s_mean += np.mean(tmp_s_mean)\n",
    "                epoch_s_std += np.mean(tmp_s_std)\n",
    "                epoch_s_cost += tmp_s_cost\n",
    "        print(\"adjust a_cost\")                  \n",
    "        epoch_a_cost /= num_batch\n",
    "        if itr % self.display_step == 0:\n",
    "            print (\"Training //\", \"Epoch %d //\" % itr, \" Total r_cost = %.5f\" % epoch_r_cost,\n",
    "                   \" Total s_cost = %.5f\" % epoch_s_cost,\n",
    "                   \" Total s_mean = %.5f\" % epoch_s_mean,\n",
    "                   \" Total s_std = %.5f\" % epoch_s_std,\n",
    "                   \" Total a_cost = %.5f\" % epoch_a_cost,\n",
    "                   \"Training time : %d ms\" % (time.time() * 1000.0 - start_time),\n",
    "                   \"negative Sampling time : %d ms\" % (NS_end_time - NS_start_time),\n",
    "                   \"negative samples : %d\" % (num_sample))\n",
    "\n",
    "    def test_model(self, itr):  # calculate the cost and rmse of testing set in each epoch\n",
    "        if itr % self.display_step == 0:\n",
    "            start_time = time.time() * 1000.0\n",
    "            P, Q = self.sess.run([self.P, self.Q])\n",
    "            Rec = np.matmul(P, Q.T)\n",
    "\n",
    "            [precision, recall, f_score, NDCG] = utility.test_model_all(Rec, self.vali_df, self.train_df)\n",
    "            utility.ranking_analysis(Rec, self.vali_df, self.train_df, self.key_genre, self.item_genre_list,\n",
    "                                     self.user_genre_count)\n",
    "            print(\"testing computation done\")\n",
    "            avg_genre = []\n",
    "            for k in range(self.num_genre):\n",
    "                avg_genre.append(np.sum(Rec * self.item_genre[:, k].reshape((1, self.num_cols)))\n",
    "                                 / (self.genre_count_list[k] * self.num_rows))\n",
    "\n",
    "            std_avg_genre = np.std(avg_genre)\n",
    "            print (\n",
    "                \"Testing //\", \"Epoch %d //\" % itr,\n",
    "                \"Testing time : %d ms\" % (time.time() * 1000.0 - start_time))\n",
    "            print(\"avg rating genre: \" + str(avg_genre))\n",
    "            print(\"std of avg rating genre\" + str(std_avg_genre))\n",
    "            print(\"=\" * 200)\n",
    "\n",
    "    def make_records(self):  # record all the results' details into files\n",
    "        P, Q = self.sess.run([self.P, self.Q])\n",
    "        Rec = np.matmul(P, Q.T)\n",
    "\n",
    "        [precision, recall, f_score, NDCG] = utility.test_model_all(Rec, self.vali_df, self.train_df)\n",
    "        return precision, recall, f_score, NDCG, Rec\n",
    "\n",
    "    @staticmethod\n",
    "    def l2_norm(tensor):\n",
    "        return tf.reduce_sum(tf.square(tensor))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5c09210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='DPR_REO')\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('--train_epoch', type=int, default=0)\n",
    "parser.add_argument('--train_epoch_a', type=int, default=20)\n",
    "parser.add_argument('--display_step', type=int, default=1)\n",
    "parser.add_argument('--lr_r', type=float, default=0.01)\n",
    "parser.add_argument('--lr_a', type=float, default=0.005)\n",
    "parser.add_argument('--reg', type=float, default=0.1)\n",
    "parser.add_argument('--reg_s', type=float, default=30)\n",
    "parser.add_argument('--hidden_neuron', type=int, default=20)\n",
    "parser.add_argument('--n', type=int, default=1)\n",
    "parser.add_argument('--neg', type=int, default=5)\n",
    "parser.add_argument('--alpha', type=float, default=1000.0)\n",
    "parser.add_argument('--batch_size', type=int, default=1024)\n",
    "parser.add_argument('--layers', nargs='?', default='[50, 50, 50, 50]')\n",
    "parser.add_argument('--dataname', nargs='?', default='ml1m-6')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6d483b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(r'ml1m-6/training_df.pkl')\n",
    "vali_df = pd.read_pickle(r'ml1m-6/valiing_df.pkl')   # for validation\n",
    "# vali_df = pickle.load(open('./' + dataname + '/testing_df.pkl'))  # for testing\n",
    "key_genre = pd.read_pickle(r'ml1m-6/key_genre.pkl')\n",
    "item_idd_genre_list = pd.read_pickle(r'ml1m-6/item_idd_genre_list.pkl')\n",
    "genre_item_vector = pd.read_pickle(r'ml1m-6/genre_item_vector.pkl')\n",
    "genre_count = pd.read_pickle(r'ml1m-6/genre_count.pkl')\n",
    "user_genre_count = pd.read_pickle(r'ml1m-6/user_genre_count.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b4e58a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "number of positive feedback: 370229\n",
      "estimated number of training samples: 1851145\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_item = len(train_df['item_id'].unique())\n",
    "num_user = len(train_df['user_id'].unique())\n",
    "num_genre = len(key_genre)\n",
    "\n",
    "item_genre_list = []\n",
    "for u in range(num_item):\n",
    "    gl = item_idd_genre_list[u]\n",
    "    tmp = []\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            tmp.append(g)\n",
    "    item_genre_list.append(tmp)\n",
    "\n",
    "print('!' * 100)\n",
    "print('number of positive feedback: ' + str(len(train_df)))\n",
    "print('estimated number of training samples: ' + str(args.neg * len(train_df)))\n",
    "print('!' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e3e94ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre = np.zeros((num_item, num_genre))\n",
    "for i in range(num_item):\n",
    "    gl = item_genre_list[i]\n",
    "    for k in range(num_genre):\n",
    "        if key_genre[k] in gl:\n",
    "            item_genre[i, k] = 1.0\n",
    "\n",
    "genre_count_mean_reciprocal = []\n",
    "\n",
    "##there are six key_genre --> in the training dataset, count the number of movies for each genre\n",
    "#genre_count = dictionary with number of movies for each keygrenre\n",
    "for k in key_genre:\n",
    "    genre_count_mean_reciprocal.append(1.0 / genre_count[k])\n",
    "genre_count_mean_reciprocal = (np.array(genre_count_mean_reciprocal)).reshape((num_genre, 1))\n",
    "genre_error_weight = np.dot(item_genre, genre_count_mean_reciprocal)\n",
    "\n",
    "args.num_genre = num_genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "54d0117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********DPR_REO**********\n",
      "Namespace(f='/home/vuhoang181/.local/share/jupyter/runtime/kernel-2aaa66f4-45f7-4b84-8d88-9ed21cb2aec6.json', train_epoch=0, train_epoch_a=20, display_step=1, lr_r=0.01, lr_a=0.005, reg=0.1, reg_s=30, hidden_neuron=20, n=1, neg=5, alpha=1000.0, batch_size=1024, layers='[50, 50, 50, 50]', dataname='ml1m-6', num_genre=6)\n",
      "INFO:tensorflow:Restoring parameters from ./ml1m-6/BPR_check_points/check_point.ckpt-30\n",
      "restore done\n",
      "starting itr 1\n",
      "start itr 1for batch 0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Reshape_28' defined at (most recent call last):\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_36392/262190402.py\", line 13, in <module>\n      dpr = DPR_REO(sess, args, train_df, vali_df, item_genre, genre_error_weight,\n    File \"/tmp/ipykernel_36392/3886630908.py\", line 49, in __init__\n      self._prepare_model()\n    File \"/tmp/ipykernel_36392/3886630908.py\", line 149, in _prepare_model\n      adv_last = tf.reshape(tf.concat([predict_pos, predict_neg], axis=0), [tf.shape(self.input_item_genre)[0], 1])\nNode: 'Reshape_28'\nInput to reshape is a tensor with 2048 values, but the requested shape has 1024\n\t [[{{node Reshape_28}}]]\n\nOriginal stack trace for 'Reshape_28':\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n    app.start()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n    result = self._run_cell(\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_36392/262190402.py\", line 13, in <module>\n    dpr = DPR_REO(sess, args, train_df, vali_df, item_genre, genre_error_weight,\n  File \"/tmp/ipykernel_36392/3886630908.py\", line 49, in __init__\n    self._prepare_model()\n  File \"/tmp/ipykernel_36392/3886630908.py\", line 149, in _prepare_model\n    adv_last = tf.reshape(tf.concat([predict_pos, predict_neg], axis=0), [tf.shape(self.input_item_genre)[0], 1])\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 199, in reshape\n    result = gen_array_ops.reshape(tensor, shape, name)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8551, in reshape\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3798, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1360\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1362\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1453\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1454\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1455\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 2048 values, but the requested shape has 1024\n\t [[{{node Reshape_28}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36392/262190402.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         dpr = DPR_REO(sess, args, train_df, vali_df, item_genre, genre_error_weight,\n\u001b[1;32m     14\u001b[0m                       key_genre, item_genre_list, user_genre_count)\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mprec_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndcg_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRec\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         [RSP_one, REO_one] = utility.ranking_analysis(Rec, vali_df, train_df, key_genre, item_genre_list,\n\u001b[1;32m     17\u001b[0m                                                       user_genre_count)\n",
      "\u001b[0;32m/tmp/ipykernel_36392/3886630908.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch_itr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"starting itr \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch_itr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_36392/3886630908.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, itr)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         \u001b[0mbatch_idx_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_idx_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mitem_idx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_pos_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     a_opt, tmp_a_cost, p, q_pos,q_neg, predict_pos, adv_last_prem,adv_last, adv_output = self.sess.run(  # do the optimization by the minibatch\n\u001b[0m\u001b[1;32m    200\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_last_prem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_last\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_output\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#update the adversary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                         feed_dict={self.user_input: user_list[batch_idx_a, :],\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    969\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    970\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1192\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1372\u001b[0m                            run_metadata)\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1395\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1397\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Reshape_28' defined at (most recent call last):\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_36392/262190402.py\", line 13, in <module>\n      dpr = DPR_REO(sess, args, train_df, vali_df, item_genre, genre_error_weight,\n    File \"/tmp/ipykernel_36392/3886630908.py\", line 49, in __init__\n      self._prepare_model()\n    File \"/tmp/ipykernel_36392/3886630908.py\", line 149, in _prepare_model\n      adv_last = tf.reshape(tf.concat([predict_pos, predict_neg], axis=0), [tf.shape(self.input_item_genre)[0], 1])\nNode: 'Reshape_28'\nInput to reshape is a tensor with 2048 values, but the requested shape has 1024\n\t [[{{node Reshape_28}}]]\n\nOriginal stack trace for 'Reshape_28':\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n    app.start()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n    result = self._run_cell(\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n    return runner(coro)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_36392/262190402.py\", line 13, in <module>\n    dpr = DPR_REO(sess, args, train_df, vali_df, item_genre, genre_error_weight,\n  File \"/tmp/ipykernel_36392/3886630908.py\", line 49, in __init__\n    self._prepare_model()\n  File \"/tmp/ipykernel_36392/3886630908.py\", line 149, in _prepare_model\n    adv_last = tf.reshape(tf.concat([predict_pos, predict_neg], axis=0), [tf.shape(self.input_item_genre)[0], 1])\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 199, in reshape\n    result = gen_array_ops.reshape(tensor, shape, name)\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8551, in reshape\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/vuhoang181/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3798, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "precision = np.zeros(4)\n",
    "recall = np.zeros(4)\n",
    "f1 = np.zeros(4)\n",
    "ndcg = np.zeros(4)\n",
    "RSP = np.zeros(4)\n",
    "REO = np.zeros(4)\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "n = args.n\n",
    "for i in range(n):\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        dpr = DPR_REO(sess, args, train_df, vali_df, item_genre, genre_error_weight,\n",
    "                      key_genre, item_genre_list, user_genre_count)\n",
    "        [prec_one, rec_one, f_one, ndcg_one, Rec] = dpr.run()\n",
    "        [RSP_one, REO_one] = utility.ranking_analysis(Rec, vali_df, train_df, key_genre, item_genre_list,\n",
    "                                                      user_genre_count)\n",
    "        precision += prec_one\n",
    "        recall += rec_one\n",
    "        f1 += f_one\n",
    "        ndcg += ndcg_one\n",
    "        RSP += RSP_one\n",
    "        REO += REO_one\n",
    "\n",
    "with open('Rec_' + dataname + '_DPR_REO.mat', \"wb\") as f:\n",
    "    np.save(f, Rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "894798eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "Averaged precision@1\t0.0000000,\t||\tprecision@5\t0.0000000,\t||\tprecision@10\t0.0000000,\t||\tprecision@15\t0.0000000\n",
      "Averaged recall@1\t0.0000000,\t||\trecall@5\t0.0000000,\t||\trecall@10\t0.0000000,\t||\trecall@15\t0.0000000\n",
      "Averaged f1@1\t\t0.0000000,\t||\tf1@5\t\t0.0000000,\t||\tf1@10\t\t0.0000000,\t||\tf1@15\t\t0.0000000\n",
      "Averaged NDCG@1\t\t0.0000000,\t||\tNDCG@5\t\t0.0000000,\t||\tNDCG@10\t\t0.0000000,\t||\tNDCG@15\t\t0.0000000\n",
      "****************************************************************************************************\n",
      "Averaged RSP    @1\t0.0000000\t||\t@5\t0.0000000\t||\t@10\t0.0000000\t||\t@15\t0.0000000\n",
      "Averaged REO @1\t0.0000000\t||\t@5\t0.0000000\t||\t@10\t0.0000000\t||\t@15\t0.0000000\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "precision /= n\n",
    "recall /= n\n",
    "f1 /= n\n",
    "ndcg /= n\n",
    "RSP /= n\n",
    "REO /= n\n",
    "\n",
    "print('')\n",
    "print('*' * 100)\n",
    "print('Averaged precision@1\\t%.7f,\\t||\\tprecision@5\\t%.7f,\\t||\\tprecision@10\\t%.7f,\\t||\\tprecision@15\\t%.7f' \\\n",
    "      % (precision[0], precision[1], precision[2], precision[3]))\n",
    "print('Averaged recall@1\\t%.7f,\\t||\\trecall@5\\t%.7f,\\t||\\trecall@10\\t%.7f,\\t||\\trecall@15\\t%.7f' \\\n",
    "      % (recall[0], recall[1], recall[2], recall[3]))\n",
    "print('Averaged f1@1\\t\\t%.7f,\\t||\\tf1@5\\t\\t%.7f,\\t||\\tf1@10\\t\\t%.7f,\\t||\\tf1@15\\t\\t%.7f' \\\n",
    "      % (f1[0], f1[1], f1[2], f1[3]))\n",
    "print('Averaged NDCG@1\\t\\t%.7f,\\t||\\tNDCG@5\\t\\t%.7f,\\t||\\tNDCG@10\\t\\t%.7f,\\t||\\tNDCG@15\\t\\t%.7f' \\\n",
    "      % (ndcg[0], ndcg[1], ndcg[2], ndcg[3]))\n",
    "print('*' * 100)\n",
    "print('Averaged RSP    @1\\t%.7f\\t||\\t@5\\t%.7f\\t||\\t@10\\t%.7f\\t||\\t@15\\t%.7f' \\\n",
    "      % (RSP[0], RSP[1], RSP[2], RSP[3]))\n",
    "print('Averaged REO @1\\t%.7f\\t||\\t@5\\t%.7f\\t||\\t@10\\t%.7f\\t||\\t@15\\t%.7f' \\\n",
    "      % (REO[0], REO[1], REO[2], REO[3]))\n",
    "print('*' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bb46e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 % 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48113f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a6036433",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = len(train_df['item_id'].unique())\n",
    "num_rows = len(train_df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5a042539",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 =tf.compat.v1.get_variable(name=\"P1\",\n",
    "                                     initializer=tf.compat.v1.truncated_normal(shape=[num_rows, 20], mean=0,\n",
    "                                                                               stddev=0.03), dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67c33b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q =tf.compat.v1.get_variable(name=\"Q\",\n",
    "                                     initializer=tf.compat.v1.truncated_normal(shape=[num_cols, 20], mean=0,\n",
    "                                                                               stddev=0.03), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "43f99526",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=tf.compat.v1.placeholder(tf.int32, shape=[None, 1], name=\"user_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ef52ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_input_pos = tf.compat.v1.placeholder(tf.int32, shape=[None, 1], name=\"item_input_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "629f4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_item_genre = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, 6]\n",
    "                                                   , name=\"input_item_genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ab69cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.reduce_sum(tf.nn.embedding_lookup(P1, user_input), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df9a98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pos = tf.reduce_sum(tf.nn.embedding_lookup(Q, item_input_pos), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "32b70bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_175:0' shape=(None, 20) dtype=float32>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "66fb0572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_176:0' shape=(None, 20) dtype=float32>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "74b35ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_pos = tf.reduce_sum(p * q_pos, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "053c9f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_177:0' shape=(None,) dtype=float32>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0c3d9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_last = tf.reshape(predict_pos, [tf.shape(input_item_genre)[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "499949d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_18:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c6952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
